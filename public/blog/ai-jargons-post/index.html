<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Understanding AI Jargons | Amish Kushwaha</title>
<meta name="keywords" content="AI, ML">
<meta name="description" content="Simply understanding some common AI jargons that float around">
<meta name="author" content="">
<link rel="canonical" href="http://localhost:1313/blog/ai-jargons-post/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.45e028aa8ce0961349adf411b013ee39406be2c0bc80d4ea3fc04555f7f4611a.css" integrity="sha256-ReAoqozglhNJrfQRsBPuOUBr4sC8gNTqP8BFVff0YRo=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/blog/ai-jargons-post/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:url" content="http://localhost:1313/blog/ai-jargons-post/">
  <meta property="og:site_name" content="Amish Kushwaha">
  <meta property="og:title" content="Understanding AI Jargons">
  <meta property="og:description" content="Simply understanding some common AI jargons that float around">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="blog">
    <meta property="article:published_time" content="2025-02-09T12:00:00+05:30">
    <meta property="article:modified_time" content="2025-02-09T12:00:00+05:30">
    <meta property="article:tag" content="AI">
    <meta property="article:tag" content="ML">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Understanding AI Jargons">
<meta name="twitter:description" content="Simply understanding some common AI jargons that float around">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Blogs",
      "item": "http://localhost:1313/blog/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Understanding AI Jargons",
      "item": "http://localhost:1313/blog/ai-jargons-post/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Understanding AI Jargons",
  "name": "Understanding AI Jargons",
  "description": "Simply understanding some common AI jargons that float around",
  "keywords": [
    "AI", "ML"
  ],
  "articleBody": "Base Model It is huge neural network which is trained on entire data available on the internet. it’s main objective is to complete text. At this stage it is not very impressive or useful. It is just a first step toward modern LLMs that we as end users are used to interating with (called Chat Models)\nChat Model It is an AI assistant which is fine tuned to interact with users in a useful, structured and context aware manner (example ChatGPT). It is trained to understand and follow instructions, answer targeted questions and assist in a meaningfull manner unlike a Base Model that simply predicts and completes text. A Base Model can be transformed into a Chat Model by :\nSupervised Fine Tuning (SFT) : Based mode is trained on high quality examples of human demonstrations.\nReinforcement Learning from Human Feedback (RLHF) : Generated responses from the model are refined/optimized based on human rating. Note : Generally, SFT is followed by RLHF.\nSupervised Fine Tuning (SFT) It transforms a Base Model into a Chat Model. This is achieved by training the base model on carefully crafted high quality human written conversation. Basically a humans forms some questions and write a perfect answer! This way humans create a huge dataset (human crafted dataset) of such conversations or dialogues which basically guides it to follow instructions, give meaningful answers and engage the user meaningfully.\nReinforcement Learning from Human Feedback (RLHF) This is generally followed after SFT where the LLM, now capable of giving meaningful answers, is oriented / refined to suit human prefrences so that final response is more accurate and natural and safe. Unlike normal Reinforcement Learning which is good for cases like training a model to play a game - where it gets reward for a win and penalized for a loss, but in this case of LLM answering a question, it is quite tricky to define a reward / penalty system; that is where RLHF comes in, which is a clever way to improve performance. It works like so\nLLM generates multple responses for a user’s prompt Humans rank these responses from best to worst (based on correctness, quality, format, etc) Above step is slow and hard to achieve at scale so a seperate model is trained (Reward Model) to do predict response rankings like humans. After Reward Model is ready is it used to fine tune the LLM using reinforcement learning. The end result is an Chat Model Reasoning Model They incorporate an intermediate step between receiving a question and answering. Unlike a Chat Model they simply don’t go from Question to Answer by predicting it, instead they include a step for thinking (Question —\u003e Think —\u003e Answer) through the problem before responding. The thinking or reasoning step allows them to break down complex problems and explain their thought process. (example, ChatGpt-o3 and DeepSeek-R1). These resoning model are particularly good with coding, puzzle solving, mathematical problems, etc. Some cons of these reasoning models are:\nHave a higher inference time. Have a higher computational cost associated with their responses. A normal LLM / Chat Model can be encouraged to reason step by step through simple prompt engineering technique called Chain of Thought. Which makes the model to generate intermediate reasoning steps before infering. Simple trick involves adding “Let’s think step by step” to the prompt.\n",
  "wordCount" : "556",
  "inLanguage": "en",
  "datePublished": "2025-02-09T12:00:00+05:30",
  "dateModified": "2025-02-09T12:00:00+05:30",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/blog/ai-jargons-post/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Amish Kushwaha",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Amish Kushwaha (Alt + H)">Amish Kushwaha</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/home/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/education/" title="Education">
                    <span>Education</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/experience/" title="Experience">
                    <span>Experience</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/projects/" title="Projects">
                    <span>Projects</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/blog/" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://localhost:1313/">Home</a>&nbsp;»&nbsp;<a href="http://localhost:1313/blog/">Blogs</a></div>
    <h1 class="post-title entry-hint-parent">
      Understanding AI Jargons
    </h1>
    <div class="post-meta"><span title='2025-02-09 12:00:00 +0530 +0530'>February 9, 2025</span>

</div>
  </header> <div class="toc">
    <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#base-model" aria-label="Base Model">Base Model</a></li>
                <li>
                    <a href="#chat-model" aria-label="Chat Model">Chat Model</a><ul>
                        
                <li>
                    <a href="#supervised-fine-tuning-sft" aria-label="Supervised Fine Tuning (SFT)">Supervised Fine Tuning (SFT)</a></li>
                <li>
                    <a href="#reinforcement-learning-from-human-feedback-rlhf" aria-label="Reinforcement Learning from Human Feedback (RLHF)">Reinforcement Learning from Human Feedback (RLHF)</a></li></ul>
                </li>
                <li>
                    <a href="#reasoning-model" aria-label="Reasoning Model">Reasoning Model</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h3 id="base-model">Base Model<a hidden class="anchor" aria-hidden="true" href="#base-model">#</a></h3>
<p>It is huge neural network which is trained on entire data available on the internet. it’s main objective is to complete text. At this stage it is not very impressive or useful. It is just a first step toward modern LLMs that we as end users are used to interating with (called Chat Models)</p>
<h3 id="chat-model">Chat Model<a hidden class="anchor" aria-hidden="true" href="#chat-model">#</a></h3>
<p>It is an AI assistant which is fine tuned to interact with users in a useful, structured and context aware manner (example ChatGPT). It is trained to understand and follow instructions, answer targeted questions and assist in a meaningfull manner unlike a Base Model that simply predicts and completes text. A Base Model can be transformed into a Chat Model by :<br></p>
<ol>
<li><strong>Supervised Fine Tuning (SFT)</strong> : Based mode is trained on high quality examples of human demonstrations.<br></li>
<li><strong>Reinforcement Learning from Human Feedback (RLHF)</strong> : Generated responses from the model are refined/optimized based on human rating.</li>
</ol>
<p>Note : Generally, SFT is followed by RLHF.</p>
<h4 id="supervised-fine-tuning-sft">Supervised Fine Tuning (SFT)<a hidden class="anchor" aria-hidden="true" href="#supervised-fine-tuning-sft">#</a></h4>
<p>It transforms a Base Model into a Chat Model. This is achieved by training the base model on carefully crafted high quality human written conversation. Basically a humans forms some questions and write a perfect answer! This way humans create a huge dataset <strong>(human crafted dataset)</strong> of such conversations or dialogues which basically guides it to follow instructions, give meaningful answers and engage the user meaningfully.</p>
<h4 id="reinforcement-learning-from-human-feedback-rlhf">Reinforcement Learning from Human Feedback (RLHF)<a hidden class="anchor" aria-hidden="true" href="#reinforcement-learning-from-human-feedback-rlhf">#</a></h4>
<p>This is generally followed after SFT where the LLM, now capable of giving meaningful answers, is oriented  / refined to suit human prefrences so that final response is more accurate and natural and safe. Unlike normal Reinforcement Learning which is good for cases like training a model to play a game - where it gets reward for a win and penalized for a loss, but in this case of LLM answering a question, it is quite tricky to define a reward / penalty system; that is where RLHF comes in, which is a clever way to improve performance. It works like so</p>
<ol>
<li>LLM generates multple responses for a user’s prompt</li>
<li>Humans rank these responses from best to worst (based on correctness, quality, format, etc)</li>
<li>Above step is slow and hard to achieve at scale so a seperate model is trained <strong>(Reward Model)</strong> to do predict response rankings like humans.</li>
<li>After Reward Model is ready is it used to fine tune the LLM using reinforcement learning.</li>
<li>The end result is an Chat Model</li>
</ol>
<h3 id="reasoning-model">Reasoning Model<a hidden class="anchor" aria-hidden="true" href="#reasoning-model">#</a></h3>
<p>They incorporate an intermediate step between receiving a question and answering. Unlike a Chat Model they simply don’t go from Question to Answer by predicting it, instead they include a step for thinking <strong>(Question —&gt; Think —&gt; Answer)</strong> through the problem before responding. The thinking or reasoning step allows them to break down complex problems and explain their thought process. (example, ChatGpt-o3 and DeepSeek-R1). These resoning model are particularly good with coding, puzzle solving, mathematical problems, etc. Some cons of these reasoning models are:</p>
<ul>
<li>Have a higher inference time.</li>
<li>Have a higher computational cost associated with their responses.</li>
</ul>
<p>A normal LLM / Chat Model can be encouraged to reason step by step through simple prompt engineering technique called <strong>Chain of Thought</strong>. Which makes the model to generate intermediate reasoning steps before infering. Simple trick involves adding <strong>“Let’s think step by step”</strong> to the prompt.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:1313/tags/ai/">AI</a></li>
      <li><a href="http://localhost:1313/tags/ml/">ML</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:1313/">Amish Kushwaha</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
