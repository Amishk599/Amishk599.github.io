<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Understanding AI Jargons | Amish Kushwaha</title>
<meta name=keywords content="AI,ML"><meta name=description content="Simply understanding some common AI jargons that float around"><meta name=author content><link rel=canonical href=https://amishk599.github.io/blog/ai-jargons-post/><link crossorigin=anonymous href=/assets/css/stylesheet.45e028aa8ce0961349adf411b013ee39406be2c0bc80d4ea3fc04555f7f4611a.css integrity="sha256-ReAoqozglhNJrfQRsBPuOUBr4sC8gNTqP8BFVff0YRo=" rel="preload stylesheet" as=style><link rel=icon href=https://amishk599.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://amishk599.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://amishk599.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://amishk599.github.io/apple-touch-icon.png><link rel=mask-icon href=https://amishk599.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://amishk599.github.io/blog/ai-jargons-post/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://amishk599.github.io/blog/ai-jargons-post/"><meta property="og:site_name" content="Amish Kushwaha"><meta property="og:title" content="Understanding AI Jargons"><meta property="og:description" content="Simply understanding some common AI jargons that float around"><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="blog"><meta property="article:published_time" content="2025-02-09T12:00:00+05:30"><meta property="article:modified_time" content="2025-02-09T12:00:00+05:30"><meta property="article:tag" content="AI"><meta property="article:tag" content="ML"><meta name=twitter:card content="summary"><meta name=twitter:title content="Understanding AI Jargons"><meta name=twitter:description content="Simply understanding some common AI jargons that float around"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blogs","item":"https://amishk599.github.io/blog/"},{"@type":"ListItem","position":2,"name":"Understanding AI Jargons","item":"https://amishk599.github.io/blog/ai-jargons-post/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Understanding AI Jargons","name":"Understanding AI Jargons","description":"Simply understanding some common AI jargons that float around","keywords":["AI","ML"],"articleBody":"Base Model It is huge neural network which is trained on entire data available on the internet. it’s main objective is to complete text. At this stage it is not very impressive or useful. It is just a first step toward modern LLMs that we as end users are used to interating with (called Chat Models)\nChat Model It is an AI assistant which is fine tuned to interact with users in a useful, structured and context aware manner (example ChatGPT). It is trained to understand and follow instructions, answer targeted questions and assist in a meaningfull manner unlike a Base Model that simply predicts and completes text. A Base Model can be transformed into a Chat Model by :\nSupervised Fine Tuning (SFT) : Based mode is trained on high quality examples of human demonstrations.\nReinforcement Learning from Human Feedback (RLHF) : Generated responses from the model are refined/optimized based on human rating. Note : Generally, SFT is followed by RLHF.\nSupervised Fine Tuning (SFT) It transforms a Base Model into a Chat Model. This is achieved by training the base model on carefully crafted high quality human written conversation. Basically a humans forms some questions and write a perfect answer! This way humans create a huge dataset (human crafted dataset) of such conversations or dialogues which basically guides it to follow instructions, give meaningful answers and engage the user meaningfully.\nReinforcement Learning from Human Feedback (RLHF) This is generally followed after SFT where the LLM, now capable of giving meaningful answers, is oriented / refined to suit human prefrences so that final response is more accurate and natural and safe. Unlike normal Reinforcement Learning which is good for cases like training a model to play a game - where it gets reward for a win and penalized for a loss, but in this case of LLM answering a question, it is quite tricky to define a reward / penalty system; that is where RLHF comes in, which is a clever way to improve performance. It works like so\nLLM generates multple responses for a user’s prompt Humans rank these responses from best to worst (based on correctness, quality, format, etc) Above step is slow and hard to achieve at scale so a seperate model is trained (Reward Model) to do predict response rankings like humans. After Reward Model is ready is it used to fine tune the LLM using reinforcement learning. The end result is an Chat Model Reasoning Model They incorporate an intermediate step between receiving a question and answering. Unlike a Chat Model they simply don’t go from Question to Answer by predicting it, instead they include a step for thinking (Question —\u003e Think —\u003e Answer) through the problem before responding. The thinking or reasoning step allows them to break down complex problems and explain their thought process. (example, ChatGpt-o3 and DeepSeek-R1). These resoning model are particularly good with coding, puzzle solving, mathematical problems, etc. Some cons of these reasoning models are:\nHave a higher inference time. Have a higher computational cost associated with their responses. A normal LLM / Chat Model can be encouraged to reason step by step through simple prompt engineering technique called Chain of Thought. Which makes the model to generate intermediate reasoning steps before infering. Simple trick involves adding “Let’s think step by step” to the prompt.\n","wordCount":"556","inLanguage":"en","datePublished":"2025-02-09T12:00:00+05:30","dateModified":"2025-02-09T12:00:00+05:30","mainEntityOfPage":{"@type":"WebPage","@id":"https://amishk599.github.io/blog/ai-jargons-post/"},"publisher":{"@type":"Organization","name":"Amish Kushwaha","logo":{"@type":"ImageObject","url":"https://amishk599.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://amishk599.github.io/ accesskey=h title="Amish Kushwaha (Alt + H)">Amish Kushwaha</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://amishk599.github.io/home/ title=Home><span>Home</span></a></li><li><a href=https://amishk599.github.io/education/ title=Education><span>Education</span></a></li><li><a href=https://amishk599.github.io/experience/ title=Experience><span>Experience</span></a></li><li><a href=https://amishk599.github.io/projects/ title=Projects><span>Projects</span></a></li><li><a href=https://amishk599.github.io/blog/ title=Blog><span>Blog</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://amishk599.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://amishk599.github.io/blog/>Blogs</a></div><h1 class="post-title entry-hint-parent">Understanding AI Jargons</h1><div class=post-meta><span title='2025-02-09 12:00:00 +0530 +0530'>February 9, 2025</span></div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#base-model aria-label="Base Model">Base Model</a></li><li><a href=#chat-model aria-label="Chat Model">Chat Model</a><ul><li><a href=#supervised-fine-tuning-sft aria-label="Supervised Fine Tuning (SFT)">Supervised Fine Tuning (SFT)</a></li><li><a href=#reinforcement-learning-from-human-feedback-rlhf aria-label="Reinforcement Learning from Human Feedback (RLHF)">Reinforcement Learning from Human Feedback (RLHF)</a></li></ul></li><li><a href=#reasoning-model aria-label="Reasoning Model">Reasoning Model</a></li></ul></div></details></div><div class=post-content><h3 id=base-model>Base Model<a hidden class=anchor aria-hidden=true href=#base-model>#</a></h3><p>It is huge neural network which is trained on entire data available on the internet. it’s main objective is to complete text. At this stage it is not very impressive or useful. It is just a first step toward modern LLMs that we as end users are used to interating with (called Chat Models)</p><h3 id=chat-model>Chat Model<a hidden class=anchor aria-hidden=true href=#chat-model>#</a></h3><p>It is an AI assistant which is fine tuned to interact with users in a useful, structured and context aware manner (example ChatGPT). It is trained to understand and follow instructions, answer targeted questions and assist in a meaningfull manner unlike a Base Model that simply predicts and completes text. A Base Model can be transformed into a Chat Model by :<br></p><ol><li><strong>Supervised Fine Tuning (SFT)</strong> : Based mode is trained on high quality examples of human demonstrations.<br></li><li><strong>Reinforcement Learning from Human Feedback (RLHF)</strong> : Generated responses from the model are refined/optimized based on human rating.</li></ol><p>Note : Generally, SFT is followed by RLHF.</p><h4 id=supervised-fine-tuning-sft>Supervised Fine Tuning (SFT)<a hidden class=anchor aria-hidden=true href=#supervised-fine-tuning-sft>#</a></h4><p>It transforms a Base Model into a Chat Model. This is achieved by training the base model on carefully crafted high quality human written conversation. Basically a humans forms some questions and write a perfect answer! This way humans create a huge dataset <strong>(human crafted dataset)</strong> of such conversations or dialogues which basically guides it to follow instructions, give meaningful answers and engage the user meaningfully.</p><h4 id=reinforcement-learning-from-human-feedback-rlhf>Reinforcement Learning from Human Feedback (RLHF)<a hidden class=anchor aria-hidden=true href=#reinforcement-learning-from-human-feedback-rlhf>#</a></h4><p>This is generally followed after SFT where the LLM, now capable of giving meaningful answers, is oriented / refined to suit human prefrences so that final response is more accurate and natural and safe. Unlike normal Reinforcement Learning which is good for cases like training a model to play a game - where it gets reward for a win and penalized for a loss, but in this case of LLM answering a question, it is quite tricky to define a reward / penalty system; that is where RLHF comes in, which is a clever way to improve performance. It works like so</p><ol><li>LLM generates multple responses for a user’s prompt</li><li>Humans rank these responses from best to worst (based on correctness, quality, format, etc)</li><li>Above step is slow and hard to achieve at scale so a seperate model is trained <strong>(Reward Model)</strong> to do predict response rankings like humans.</li><li>After Reward Model is ready is it used to fine tune the LLM using reinforcement learning.</li><li>The end result is an Chat Model</li></ol><h3 id=reasoning-model>Reasoning Model<a hidden class=anchor aria-hidden=true href=#reasoning-model>#</a></h3><p>They incorporate an intermediate step between receiving a question and answering. Unlike a Chat Model they simply don’t go from Question to Answer by predicting it, instead they include a step for thinking <strong>(Question —> Think —> Answer)</strong> through the problem before responding. The thinking or reasoning step allows them to break down complex problems and explain their thought process. (example, ChatGpt-o3 and DeepSeek-R1). These resoning model are particularly good with coding, puzzle solving, mathematical problems, etc. Some cons of these reasoning models are:</p><ul><li>Have a higher inference time.</li><li>Have a higher computational cost associated with their responses.</li></ul><p>A normal LLM / Chat Model can be encouraged to reason step by step through simple prompt engineering technique called <strong>Chain of Thought</strong>. Which makes the model to generate intermediate reasoning steps before infering. Simple trick involves adding <strong>“Let’s think step by step”</strong> to the prompt.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://amishk599.github.io/tags/ai/>AI</a></li><li><a href=https://amishk599.github.io/tags/ml/>ML</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://amishk599.github.io/>Amish Kushwaha</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>